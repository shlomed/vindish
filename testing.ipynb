{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shlomi\\AppData\\Local\\conda\\conda\\envs\\rl1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import add_features\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "PRINT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dir = \"C://Users/shlomi/Documents/Work/vindish/data/\"\n",
    "e_dir = \"E:\\\\Work/Vindish/created_samples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(np.load(e_dir + \"X.npy\")).type(torch.float32)\n",
    "y = torch.tensor(np.load(e_dir + \"y.npy\")).type(torch.float32)\n",
    "features = np.load(e_dir+\"features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49938, 10, 20]) torch.Size([49938, 5])\n",
      "torch.FloatTensor torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "print(X.type(), y.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Time_To_Expiration\n",
      "1 UX1\n",
      "2 UX2\n",
      "3 UX3\n",
      "4 UX4\n",
      "5 UX5\n",
      "6 SP500\n",
      "7 dow\n",
      "8 dom\n",
      "9 doy\n",
      "10 UX1_diff\n",
      "11 UX2_diff\n",
      "12 UX3_diff\n",
      "13 UX4_diff\n",
      "14 UX5_diff\n",
      "15 SP500_diff\n",
      "16 day_of_month\n",
      "17 day_of_week\n",
      "18 day_of_year\n",
      "19 time_of_day\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(features):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniConv2d(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiniConv2d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 5, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.conv4 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.conv5 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.conv6 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.conv7 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv7(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mini_conv2d = MiniConv2d()\n",
    "mini_conv2d(X[:3, :5].unsqueeze_(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniConv1d(torch.nn.Module):\n",
    "    def __init__(self, init_kernel_size=(3, 2)):\n",
    "        super(MiniConv1d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 5, init_kernel_size, padding=(1, 1))\n",
    "        self.conv2 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        self.conv3 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        self.conv4 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        self.conv5 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        self.conv6 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        self.conv7 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv7(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mini_conv1d = MiniConv1d()\n",
    "mini_conv1d(X[:3, :5].unsqueeze_(1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mini_conv_singles = MiniConv1d(init_kernel_size=(3,3))\n",
    "singles = X[:, :,  [0, 18, 19]].unsqueeze_(1)\n",
    "mini_conv_singles(singles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(torch.nn.Module):\n",
    "    def __init__(self, n_categories, n_dims):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(n_categories, n_dims)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "embed = torch.nn.Embedding(6, 2)\n",
    "embed(torch.tensor([[1,1,3,4], [1,1,3,4]])).shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "embed = Embeddings(7, 2)\n",
    "embed(X[:, :, 7].type(torch.long)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.mini_conv_ux = MiniConv2d()\n",
    "        self.mini_conv_ux_diffs = MiniConv2d()\n",
    "        self.mini_conv_snp = MiniConv1d()\n",
    "        self.mini_conv_singles = MiniConv1d(init_kernel_size=(3,3))\n",
    "        self.embed_dow = Embeddings(7, 3)\n",
    "        self.embed_dom = Embeddings(31, 5)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(880, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 5)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ux_vals = x[:, :, 1:6].unsqueeze_(1)\n",
    "        ux_diffs = x[:, :, 10:15].unsqueeze_(1)\n",
    "        snp_data = x[:, :, [6,15]].unsqueeze_(1)\n",
    "        singles = x[:, :,  [0, 18, 19]].unsqueeze_(1) # time_to_expiration, doy, time_of_day\n",
    "        \n",
    "        dow = x[:, :, 17].type(torch.long)\n",
    "        dom = x[:, :, 16].type(torch.long)\n",
    "        \n",
    "        x_ux = self.mini_conv_ux(ux_vals).view(x.shape[0], -1)\n",
    "        x_diffs = self.mini_conv_ux_diffs(ux_diffs).view(x.shape[0], -1)\n",
    "        x_snp = self.mini_conv_snp(snp_data).view(x.shape[0], -1)\n",
    "        x_dow = self.embed_dow(dow).view(x.shape[0], -1)\n",
    "        x_dom = self.embed_dom(dom).view(x.shape[0], -1)\n",
    "        x_singles = self.mini_conv_singles(singles).view(x.shape[0], -1)\n",
    "        \n",
    "        x = torch.cat((x_ux, x_diffs, x_snp, x_dom, x_dow, x_singles), 1)\n",
    "        \n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "betas = torch.from_numpy(np.array([0.62, 0.44, 0.32, 0.26, 0.21])).type(torch.Tensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(X.shape[0]*0.6)\n",
    "n_val = int(X.shape[0]*0.8)\n",
    "\n",
    "X_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "\n",
    "X_val = X[n_train:n_val]\n",
    "y_val = y[n_train:n_val]\n",
    "\n",
    "# dropping all end of period samples:\n",
    "ser = pd.Series(X_train[:, -1, 0].detach().numpy())\n",
    "idx_to_keep = ser[ser>0.3].index.values\n",
    "X_train = X_train[idx_to_keep]\n",
    "y_train = y_train[idx_to_keep]\n",
    "\n",
    "ser = pd.Series(X_val[:, -1, 0].detach().numpy())\n",
    "idx_to_keep = ser[ser>0.3].index.values\n",
    "X_val = X_val[idx_to_keep]\n",
    "y_val = y_val[idx_to_keep]\n",
    "\n",
    "\n",
    "X_test = X[n_val:]\n",
    "y_test = y[n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_ds = TensorDataset(X_val, y_val)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "# print(model)\n",
    "# model.fc3.weight.data = (torch.zeros_like(model.fc3.weight, requires_grad=True, device=device))\n",
    "# model.fc3.bias.data = torch.tensor([200., 0., 0., 0., 0.], requires_grad=True, device=device)\n",
    "\n",
    "model = model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit(y, x, alphas):\n",
    "    if PRINT:\n",
    "        print(\"Xs:\\n\", x[0].cpu())\n",
    "        print(\"ys:\\n\", y[0].cpu())\n",
    "\n",
    "    L3 = ((y - x)*alphas).sum(dim=1)\n",
    "\n",
    "    if PRINT:\n",
    "        print(\"L3s:\\n\", L3[:2].cpu())\n",
    "    return L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_from_200(alphas):\n",
    "    return (alphas.abs().sum(dim=1)-200.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hedging_score(alphas, betas):\n",
    "    return (alphas*betas).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(alphas, betas, x_batch, y_batch):\n",
    "    a = 1\n",
    "    b = 10\n",
    "    c = 10000\n",
    "    \n",
    "    L1 = get_dist_from_200(alphas)**2\n",
    "    L2 = get_hedging_score(alphas, betas)**2 \n",
    "    L3 = get_profit(y_batch, x_batch[:, -1, 1:6], alphas)\n",
    "    L = a*L1 + b*L2 - c*L3\n",
    "    \n",
    "#     print(L1.size(), L2.size(), L3.size())\n",
    "    \n",
    "    return L.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "losses_epoch = []\n",
    "losses_val_history = []\n",
    "mean_buy_sell_expenses = []\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.33, verbose=True)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for i, (x, y) in enumerate(train_dl):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "#         print(\"Xs:\\n\", x[:2, -1, :].cpu())\n",
    "#         print(\"ys:\\n\", y[:2, :].cpu())\n",
    "#         print(x)\n",
    "        alphas = model(x)#.type(torch.Tensor)#.to(device)        \n",
    "        loss = calc_loss(alphas, betas, x, y)\n",
    "        losses_epoch.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100==99:\n",
    "            print(np.mean(losses_epoch[-100:]))\n",
    "            \n",
    "    model.eval()\n",
    "    losses_val = []\n",
    "    L1s = []\n",
    "    L2s = []\n",
    "    profits = []\n",
    "    for x_val, y_val in val_dl:\n",
    "        x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "        alphas_val = model(x_val).type(torch.Tensor).to(device)        \n",
    "        loss_val = calc_loss(alphas_val, betas, x_val, y_val)\n",
    "        losses_val.append(loss_val.cpu().detach().numpy())\n",
    "        L1s.append(get_dist_from_200(alphas_val).cpu().detach().numpy().mean())\n",
    "        L2s.append(get_hedging_score(alphas_val, betas).cpu().detach().numpy().mean())\n",
    "        profits.append(get_profit(y_val, x_val[:, -1, 1:6], alphas_val).cpu().detach().numpy().mean())\n",
    "        mean_buy_sell_expenses.append(pd.DataFrame(alphas_val.detach().cpu().numpy()).diff().abs().sum(axis=1).mean()*10)\n",
    "    \n",
    "    mean_loss_val = np.mean(losses_val)\n",
    "    losses_val_history.append(mean_loss_val)\n",
    "    mean_buy_sell_expenses = np.mean(mean_buy_sell_expenses)\n",
    "    \n",
    "    print(mean_loss_val)\n",
    "#     print(\"losses_epoch:\", losses_epoch)\n",
    "#     print(\"losses_val_history:\", losses_val_history)\n",
    "    \n",
    "    mean_L1 = np.mean(L1s)\n",
    "    mean_L2 = np.mean(L2s)\n",
    "    mean_profit = np.mean(profits)\n",
    "    mean_profit_with_expenses = mean_profit-0.001*mean_buy_sell_expenses\n",
    "\n",
    "    mean_epoch_loss = np.mean(losses_epoch)\n",
    "    print(f\"epoch = {epoch}; mean_epoch_loss = {mean_epoch_loss:.3f}; val_loss = {mean_loss_val:.3f}; dist_from_200_loss = {mean_L1:.3f}; betas_loss = {mean_L2:.3f}; mean_buy_sell_expenses = {mean_buy_sell_expenses:.3f}; mean_profit = {mean_profit:.6f}; mean_profit_with_expenses = {mean_profit_with_expenses:.6f};\")\n",
    "    scheduler.step(mean_loss_val)\n",
    "\n",
    "    if mean_loss_val<=min(losses_val_history):\n",
    "        print(\"saving model.\")\n",
    "        save_path = f\"./model_vindish_epoch_{epoch}_train_loss_{int(mean_epoch_loss)}_val_loss{int(mean_loss_val)}.pth.tar\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        print(\"not saving model.\")\n",
    "    \n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    writer.add_scalar(\"mean_epoch_loss\", mean_epoch_loss, epoch)\n",
    "    writer.add_scalar(\"mean_loss_val\", mean_loss_val, epoch)\n",
    "    writer.add_scalar(\"dist_from_200_loss\", mean_L1, epoch)\n",
    "    writer.add_scalar(\"betas_loss\", mean_L2, epoch)\n",
    "    writer.add_scalar(\"mean_profit\", mean_profit, epoch)\n",
    "    writer.add_scalar(\"mean_profit_with_expenses\", mean_profit_with_expenses, epoch)\n",
    "    writer.add_scalar(\"mean_buy_sell_expenses\", mean_buy_sell_expenses, epoch)\n",
    "    writer.add_scalar(\"lr\", lr, epoch)\n",
    "    \n",
    "    losses_epoch = []; L1s = [];  L2s = []; profits = []; mean_buy_sell_expenses=[]\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change a, b during epochs so that profit will also be tuned during initial steps of optimization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_fc3 = list(model.fc3.parameters())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_fc3[0] = torch.zeros_like(w_fc3[0])\n",
    "w_fc3[1] = torch.zeros_like(w_fc3[1])\n",
    "w_fc3[1][0] = 200."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(model.fc3.parameters())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fc3.weight.data = (torch.zeros_like(model.fc3.weight))\n",
    "model.fc3.bias.data = torch.zeros_like(model.fc3.bias)\n",
    "model.fc3.bias[0] = 200."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = X[:64, :, :]\n",
    "y = y[:64, :]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "calc_loss(model(x), betas, x.to(device), y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "# PATH = save_path\n",
    "from glob import glob\n",
    "PATH = glob(\"model*.tar\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (mini_conv_ux): MiniConv2d(\n",
       "    (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv6): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv7): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (mini_conv_ux_diffs): MiniConv2d(\n",
       "    (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv6): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv7): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (mini_conv_snp): MiniConv1d(\n",
       "    (conv1): Conv2d(1, 5, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv6): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv7): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (mini_conv_singles): MiniConv1d(\n",
       "    (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv6): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv7): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (embed_dow): Embeddings(\n",
       "    (embed): Embedding(7, 3)\n",
       "  )\n",
       "  (embed_dom): Embeddings(\n",
       "    (embed): Embedding(31, 5)\n",
       "  )\n",
       "  (fc1): Linear(in_features=880, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATH = \"model_vindish_epoch_18_train_loss_-280_val_loss107.pth.tar\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits = []\n",
    "costs = []\n",
    "trans_cost = 0.01\n",
    "alphas_test = []\n",
    "\n",
    "x, y = next(iter(test_dl))\n",
    "x, y = x.to(device), y.to(device)\n",
    "alphas_test.append(model(x).type(torch.Tensor).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.0723355]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income = []\n",
    "outcome = []\n",
    "income.append(0)\n",
    "outcome.append(-(alphas_test[-1].abs().sum()*trans_cost).detach().cpu().numpy())\n",
    "outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33.9028, device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :, 0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                         | 0/9988 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re-buying all in i=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████████████████████████▍                                                                                                          | 3248/9988 [00:44<01:31, 73.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selling all in i=3256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████████████████▎                                                                                                         | 3308/9988 [00:44<01:30, 73.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re-buying all in i=3309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 5938/9988 [01:20<00:54, 74.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selling all in i=5943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 5995/9988 [01:20<00:53, 74.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re-buying all in i=5996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 8608/9988 [01:55<00:18, 74.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selling all in i=8610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 8658/9988 [01:56<00:17, 74.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re-buying all in i=8663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9988/9988 [02:14<00:00, 74.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total profit including costs: 2179.5163\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "flag_re_buy = True\n",
    "\n",
    "for x, y in tqdm(test_dl): # batch size is 1 for testing\n",
    "    i += 1\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    alphas_test.append(model(x).type(torch.Tensor).to(device))\n",
    "\n",
    "    if (x[0, :, 0].min()<0.3 or i==1) and not flag_re_buy:\n",
    "        print(f\"selling all in i={i}\")\n",
    "#         print(alphas_test[-2])\n",
    "#         print(y.shape)\n",
    "#         print(y)\n",
    "        income.append((alphas_test[-2]*y).sum().detach().cpu().numpy()) # may also be negative if the contract i bought doesn't profitable\n",
    "        flag_re_buy = True\n",
    "        outcome.append(-(alphas_test[-2].abs().sum()*trans_cost).detach().cpu().numpy())\n",
    "        continue\n",
    "        \n",
    "    if flag_re_buy and x[0, :, 0].min()>0.3:\n",
    "        print(f\"re-buying all in i={i}\")\n",
    "        flag_re_buy = False\n",
    "        outcome.append(-(alphas_test[-1].abs().sum()*trans_cost).detach().cpu().numpy())\n",
    "    \n",
    "    if flag_re_buy: # the case when we're in between months so we dont have any contract\n",
    "        continue\n",
    "    \n",
    "    outcome.append(-np.abs(alphas_test[-1].cpu().detach().numpy()-alphas_test[-2].cpu().detach().numpy()).sum()*trans_cost)\n",
    "    income.append(((alphas_test[-1]-alphas_test[-2])*x[:, -1, 1:6]).cpu().detach().numpy().mean())\n",
    "    \n",
    "print(\"Total profit including costs: {:.4f}\".format(sum(income+outcome)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200.024586277913 -0.6312307 [(array(746.3181, dtype=float32), 5891), (array(733.1569, dtype=float32), 8506), (array(721.41315, dtype=float32), 3256), (0.7093135, 8460), (0.583943, 8464)] 9833\n",
      "-20.508282203674263 -2.1753435 -0.0 9837\n"
     ]
    }
   ],
   "source": [
    "print(sum(income), min(income), sorted( [(x,i) for (i,x) in enumerate(income)], reverse=True )[:5], len(income))\n",
    "print(sum(outcome), min(outcome), max(outcome), len(outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha_50 = pd.Series(alphas_test)[51]#.apply(lambda x: x.cpu().detach().numpy()[0])[50]\n",
    "# alpha_50\n",
    "# len(alphas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_test[50:51]\n",
    "y = y_test[50:51]\n",
    "x, y = x.to(device), y.to(device)\n",
    "get_profit(y, x[:, -1, 1:6], alpha_50).cpu().detach().numpy().mean()\n",
    "# len(profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_test = model(x0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl1",
   "language": "python",
   "name": "rl1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
