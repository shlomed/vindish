{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import add_features\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dir = \"C://Users/shlomi/Documents/Work/vindish/data/\"\n",
    "e_dir = \"E:\\\\Work/Vindish/created_samples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(np.load(e_dir + \"X.npy\")).type(torch.float32)\n",
    "y = torch.tensor(np.load(e_dir + \"y.npy\")).type(torch.float32)\n",
    "features = np.load(e_dir+\"features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)\n",
    "print(X.type(), y.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, j in enumerate(features):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniConv2d(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiniConv2d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 5, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.conv4 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.conv5 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.conv6 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.conv7 = torch.nn.Conv2d(5, 5, 3, padding=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv7(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mini_conv2d = MiniConv2d()\n",
    "mini_conv2d(X[:3, :5].unsqueeze_(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniConv1d(torch.nn.Module):\n",
    "    def __init__(self, init_kernel_size=(3, 2)):\n",
    "        super(MiniConv1d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 5, init_kernel_size, padding=(1, 1))\n",
    "        self.conv2 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        self.conv3 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        self.conv4 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        self.conv5 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        self.conv6 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        self.conv7 = torch.nn.Conv2d(5, 5, (3, 3), padding=(1, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv7(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mini_conv1d = MiniConv1d()\n",
    "mini_conv1d(X[:3, :5].unsqueeze_(1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mini_conv_singles = MiniConv1d(init_kernel_size=(3,3))\n",
    "singles = X[:, :,  [0, 18, 19]].unsqueeze_(1)\n",
    "mini_conv_singles(singles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(torch.nn.Module):\n",
    "    def __init__(self, n_categories, n_dims):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(n_categories, n_dims)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "embed = torch.nn.Embedding(6, 2)\n",
    "embed(torch.tensor([[1,1,3,4], [1,1,3,4]])).shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "embed = Embeddings(7, 2)\n",
    "embed(X[:, :, 7].type(torch.long)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.mini_conv_ux = MiniConv2d()\n",
    "        self.mini_conv_ux_diffs = MiniConv2d()\n",
    "        self.mini_conv_snp = MiniConv1d()\n",
    "        self.mini_conv_singles = MiniConv1d(init_kernel_size=(3,3))\n",
    "        self.embed_dow = Embeddings(7, 3)\n",
    "        self.embed_dom = Embeddings(31, 5)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(880, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 5)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ux_vals = x[:, :, 1:6].unsqueeze_(1)\n",
    "        ux_diffs = x[:, :, 10:15].unsqueeze_(1)\n",
    "        snp_data = x[:, :, [6,15]].unsqueeze_(1)\n",
    "        singles = x[:, :,  [0, 18, 19]].unsqueeze_(1) # time_to_expiration, doy, time_of_day\n",
    "        \n",
    "        dow = x[:, :, 17].type(torch.long)\n",
    "        dom = x[:, :, 16].type(torch.long)\n",
    "        \n",
    "        x_ux = self.mini_conv_ux(ux_vals).view(x.shape[0], -1)\n",
    "        x_diffs = self.mini_conv_ux_diffs(ux_diffs).view(x.shape[0], -1)\n",
    "        x_snp = self.mini_conv_snp(snp_data).view(x.shape[0], -1)\n",
    "        x_dow = self.embed_dow(dow).view(x.shape[0], -1)\n",
    "        x_dom = self.embed_dom(dom).view(x.shape[0], -1)\n",
    "        x_singles = self.mini_conv_singles(singles).view(x.shape[0], -1)\n",
    "        \n",
    "        x = torch.cat((x_ux, x_diffs, x_snp, x_dom, x_dow, x_singles), 1)\n",
    "        \n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "betas = torch.from_numpy(np.array([1.,2.,3.,4.,5.])).type(torch.Tensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(X.shape[0]*0.8)\n",
    "X_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "\n",
    "X_test = X[n_train:]\n",
    "y_test = y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "# print(model)\n",
    "# model.fc3.weight.data = (torch.zeros_like(model.fc3.weight, requires_grad=True, device=device))\n",
    "# model.fc3.bias.data = torch.tensor([200., 0., 0., 0., 0.], requires_grad=True, device=device)\n",
    "\n",
    "model = model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.forward(X_train[:BATCH_SIZE]).shape, X_train[:BATCH_SIZE].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit(y, x, alphas):\n",
    "    L3 = ((y - x)*alphas).sum(dim=1)\n",
    "    return L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_from_200(alphas):\n",
    "    return (alphas.abs().sum(dim=1)-200.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hedging_score(alphas, betas):\n",
    "    return (alphas*betas).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(alphas, betas, x_batch, y_batch):\n",
    "    a = 1\n",
    "    b = 99999\n",
    "    \n",
    "    L1 = get_dist_from_200(alphas)**2\n",
    "    L2 = get_hedging_score(alphas, betas)**2 \n",
    "    L3 = get_profit(y_batch, x_batch[:, -1, :5], alphas)\n",
    "    L = (a*L1 + b*L2 - L3)\n",
    "    \n",
    "#     print(L1.size(), L2.size(), L3.size())\n",
    "    \n",
    "    return b*L2.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x.dtype, y.dtype, betas.dtype, alphas.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "losses_epoch = []\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.33, verbose=True)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for i, (x, y) in enumerate(train_dl):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "#         print(x)\n",
    "        alphas = model(x)#.type(torch.Tensor)#.to(device)        \n",
    "        loss = calc_loss(alphas, betas, x, y)\n",
    "        losses_epoch.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100==99:\n",
    "            print(np.mean(losses_epoch[-100:]))\n",
    "            \n",
    "    model.eval()\n",
    "    losses_val = []\n",
    "    L1s = []\n",
    "    L2s = []\n",
    "    profits = []\n",
    "    for x_val, y_val in test_dl:\n",
    "        x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "        alphas_val = model(x_val).type(torch.Tensor).to(device)        \n",
    "        loss_val = calc_loss(alphas_val, betas, x_val, y_val)\n",
    "        losses_val.append(loss_val.cpu().detach().numpy())\n",
    "        L1s.append(get_dist_from_200(alphas_val).sum().cpu().detach().numpy())\n",
    "        L2s.append(get_hedging_score(alphas_val, betas).sum().cpu().detach().numpy())\n",
    "        profits.append(get_profit(y_val, x_val[:, -1, :5], alphas_val).sum().cpu().detach().numpy())\n",
    "    model.train()\n",
    "    \n",
    "    mean_loss_val = np.mean(losses_val)\n",
    "    mean_L1 = np.mean(L1s)\n",
    "    mean_L2 = np.mean(L2s)\n",
    "    mean_profit = np.mean(profits)\n",
    "\n",
    "    mean_epoch_loss = np.mean(losses_epoch)\n",
    "    print(f\"epoch = {epoch}; mean_epoch_loss = {mean_epoch_loss}; val_loss = {mean_loss_val}; dist_from_200_loss = {mean_L1}; betas_loss = {mean_L2}; mean_profit = {mean_profit}\")\n",
    "    scheduler.step(mean_epoch_loss)\n",
    "    losses_epoch = []; L1s = [];  L2s = []; profits = []\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change a, b during epochs so that profit will also be tuned during initial steps of optimization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_fc3 = list(model.fc3.parameters())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_fc3[0] = torch.zeros_like(w_fc3[0])\n",
    "w_fc3[1] = torch.zeros_like(w_fc3[1])\n",
    "w_fc3[1][0] = 200."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(model.fc3.parameters())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fc3.weight.data = (torch.zeros_like(model.fc3.weight))\n",
    "model.fc3.bias.data = torch.zeros_like(model.fc3.bias)\n",
    "model.fc3.bias[0] = 200."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = X[:64, :, :]\n",
    "y = y[:64, :]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "calc_loss(model(x), betas, x.to(device), y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1",
   "language": "python",
   "name": "pytorch1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
