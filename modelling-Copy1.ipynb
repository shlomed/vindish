{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6d221a4259be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstattools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madfuller\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import add_features\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "PRINT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "\n",
    "model = Model()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.33, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Model()\n",
    "# print(model)\n",
    "# model.fc3.weight.data = (torch.zeros_like(model.fc3.weight, requires_grad=True, device=device))\n",
    "# model.fc3.bias.data = torch.tensor([200., 0., 0., 0., 0.], requires_grad=True, device=device)\n",
    "\n",
    "model = model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.forward(X_train[:BATCH_SIZE]).shape, X_train[:BATCH_SIZE].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_profit(y, x, alphas):\n",
    "    if PRINT:\n",
    "        print(\"Xs:\\n\", x[0].cpu())\n",
    "        print(\"ys:\\n\", y[0].cpu())\n",
    "\n",
    "    L3 = ((y - x)*alphas).sum(dim=1)\n",
    "\n",
    "    if PRINT:\n",
    "        print(\"L3s:\\n\", L3[:2].cpu())\n",
    "    return L3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_dist_from_200(alphas):\n",
    "    return (alphas.abs().sum(dim=1)-200.)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_hedging_score(alphas, betas):\n",
    "    return (alphas*betas).sum(dim=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def calc_loss(alphas, betas, x_batch, y_batch):\n",
    "    a = 1\n",
    "    b = 10\n",
    "    c = 10000\n",
    "    \n",
    "    L1 = get_dist_from_200(alphas)**2\n",
    "    L2 = get_hedging_score(alphas, betas)**2 \n",
    "    L3 = get_profit(y_batch, x_batch[:, -1, 1:6], alphas)\n",
    "    L = a*L1 + b*L2 - c*L3\n",
    "    \n",
    "#     print(L1.size(), L2.size(), L3.size())\n",
    "    \n",
    "    return L.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x.dtype, y.dtype, betas.dtype, alphas.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "losses_epoch = []\n",
    "losses_val_history = []\n",
    "mean_buy_sell_expenses = []\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.33, verbose=True)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for i, (x, y) in enumerate(train_dl):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "#         print(\"Xs:\\n\", x[:2, -1, :].cpu())\n",
    "#         print(\"ys:\\n\", y[:2, :].cpu())\n",
    "#         print(x)\n",
    "        alphas = model(x)#.type(torch.Tensor)#.to(device)        \n",
    "        loss = calc_loss(alphas, betas, x, y)\n",
    "        losses_epoch.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100==99:\n",
    "            print(np.mean(losses_epoch[-100:]))\n",
    "            \n",
    "    model.eval()\n",
    "    losses_val = []\n",
    "    L1s = []\n",
    "    L2s = []\n",
    "    profits = []\n",
    "    for x_val, y_val in val_dl:\n",
    "        x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "        alphas_val = model(x_val).type(torch.Tensor).to(device)        \n",
    "        loss_val = calc_loss(alphas_val, betas, x_val, y_val)\n",
    "        losses_val.append(loss_val.cpu().detach().numpy())\n",
    "        L1s.append(get_dist_from_200(alphas_val).cpu().detach().numpy().mean())\n",
    "        L2s.append(get_hedging_score(alphas_val, betas).cpu().detach().numpy().mean())\n",
    "        profits.append(get_profit(y_val, x_val[:, -1, 1:6], alphas_val).cpu().detach().numpy().mean())\n",
    "        mean_buy_sell_expenses.append(pd.DataFrame(alphas_val.detach().cpu().numpy()).diff().abs().sum(axis=1).mean()*10)\n",
    "    \n",
    "    mean_loss_val = np.mean(losses_val)\n",
    "    losses_val_history.append(mean_loss_val)\n",
    "    mean_buy_sell_expenses = np.mean(mean_buy_sell_expenses)\n",
    "    \n",
    "    print(mean_loss_val)\n",
    "#     print(\"losses_epoch:\", losses_epoch)\n",
    "#     print(\"losses_val_history:\", losses_val_history)\n",
    "    \n",
    "    mean_L1 = np.mean(L1s)\n",
    "    mean_L2 = np.mean(L2s)\n",
    "    mean_profit = np.mean(profits)\n",
    "    mean_profit_with_expenses = mean_profit-0.001*mean_buy_sell_expenses\n",
    "\n",
    "    mean_epoch_loss = np.mean(losses_epoch)\n",
    "    print(f\"epoch = {epoch}; mean_epoch_loss = {mean_epoch_loss:.3f}; val_loss = {mean_loss_val:.3f}; dist_from_200_loss = {mean_L1:.3f}; betas_loss = {mean_L2:.3f}; mean_buy_sell_expenses = {mean_buy_sell_expenses:.3f}; mean_profit = {mean_profit:.6f}; mean_profit_with_expenses = {mean_profit_with_expenses:.6f};\")\n",
    "    scheduler.step(mean_loss_val)\n",
    "\n",
    "    if mean_loss_val<=min(losses_val_history):\n",
    "        print(\"saving model.\")\n",
    "        save_path = f\"./chkpnts/model_vindish_epoch_{epoch}_train_loss_{int(mean_epoch_loss)}_val_loss{int(mean_loss_val)}.pth.tar\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        print(\"not saving model.\")\n",
    "    \n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    writer.add_scalar(\"mean_epoch_loss\", mean_epoch_loss, epoch)\n",
    "    writer.add_scalar(\"mean_loss_val\", mean_loss_val, epoch)\n",
    "    writer.add_scalar(\"dist_from_200_loss\", mean_L1, epoch)\n",
    "    writer.add_scalar(\"betas_loss\", mean_L2, epoch)\n",
    "    writer.add_scalar(\"mean_profit\", mean_profit, epoch)\n",
    "    writer.add_scalar(\"mean_profit_with_expenses\", mean_profit_with_expenses, epoch)\n",
    "    writer.add_scalar(\"mean_buy_sell_expenses\", mean_buy_sell_expenses, epoch)\n",
    "    writer.add_scalar(\"lr\", lr, epoch)\n",
    "    \n",
    "    losses_epoch = []; L1s = [];  L2s = []; profits = []; mean_buy_sell_expenses=[]\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(1+mean_profit)**(6*8*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = X_test[:2]\n",
    "# xx\n",
    "xx[:, -1, 1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = y_test[:2]\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = model.to(\"cpu\")(xx)\n",
    "print(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas.abs().cpu().detach().numpy().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas@betas.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_profit(yy, xx[:, -1, 1:6], alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change a, b during epochs so that profit will also be tuned during initial steps of optimization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_fc3 = list(model.fc3.parameters())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_fc3[0] = torch.zeros_like(w_fc3[0])\n",
    "w_fc3[1] = torch.zeros_like(w_fc3[1])\n",
    "w_fc3[1][0] = 200."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(model.fc3.parameters())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fc3.weight.data = (torch.zeros_like(model.fc3.weight))\n",
    "model.fc3.bias.data = torch.zeros_like(model.fc3.bias)\n",
    "model.fc3.bias[0] = 200."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = X[:64, :, :]\n",
    "y = y[:64, :]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "calc_loss(model(x), betas, x.to(device), y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1+0.08/200)**(6*9*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1+0.05/200)**(6*9*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### testing\n",
    "\n",
    "\n",
    "model = Model()\n",
    "# PATH = save_path\n",
    "PATH = \"model_vindish_epoch_18_train_loss_-280_val_loss107.pth.tar\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "profits = []\n",
    "costs = []\n",
    "trans_cost = 0.01\n",
    "alphas_test = []\n",
    "\n",
    "x, y = next(iter(test_dl))\n",
    "x, y = x.to(device), y.to(device)\n",
    "alphas_test.append(model(x).type(torch.Tensor).to(device))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for x, y in tqdm(test_dl): # batch size is 1 for testing\n",
    "    i += 1\n",
    "#     if i == 10:\n",
    "#         break\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    alphas_test.append(model(x).type(torch.Tensor).to(device))\n",
    "#         loss_val = calc_loss(alphas_val, betas, x_val, y_val)\n",
    "#         losses_val.append(loss_val.cpu().detach().numpy())\n",
    "#         L1s.append(get_dist_from_200(alphas_val).cpu().detach().numpy().mean())\n",
    "#         L2s.append(get_hedging_score(alphas_val, betas).cpu().detach().numpy().mean())\n",
    "    profits.append(get_profit(y, x[:, -1, 1:6], alphas_test[-1]).cpu().detach().numpy().mean())\n",
    "    costs.append(np.abs(alphas_test[-1].cpu().detach().numpy()-alphas_test[-2].cpu().detach().numpy()).sum()*trans_cost)\n",
    "\n",
    "print(\"Total profit including costs: {:.4f}\".format(sum(profits+costs)))\n",
    "pd.DataFrame({\"profits\":profits, \"costs\":costs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha_50 = pd.Series(alphas_test)[51]#.apply(lambda x: x.cpu().detach().numpy()[0])[50]\n",
    "# alpha_50\n",
    "# len(alphas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_test[50:51]\n",
    "y = y_test[50:51]\n",
    "x, y = x.to(device), y.to(device)\n",
    "get_profit(y, x[:, -1, 1:6], alpha_50).cpu().detach().numpy().mean()\n",
    "# len(profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_test = model(x0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
